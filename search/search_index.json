{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Openstack K8S Validated Architecture One","text":"<p>Based on OpenStack K8S operators from the \"main\" branch of the OpenStack Operator repo on Oct 17th, 2023</p> <p>This is a collection of CR templates that represent a validated Red Hat OpenStack Services on OpenShift deployment that has the following characteristics:</p> <ul> <li>3 master/worker combo-node OpenShift cluster</li> <li>3-replica Galera database</li> <li>RabbitMQ</li> <li>OVN networking</li> <li>Network isolation over a single NIC</li> <li>3 compute nodes</li> <li>CephHCI installed on compute nodes and used by various OSP services<ul> <li>Cinder Volume using RBD for backend</li> <li>Cinder Backup using RGW for backend</li> <li>Glance using RBD for backend</li> <li>Manila using CephFS for backend</li> <li>Nova using RBD for ephemeral storage</li> </ul> </li> </ul>"},{"location":"#considerations","title":"Considerations","text":"<ol> <li>These CRs are validated for the overall functionality of the OSP cloud deployed, but they nonetheless require customization for the particular environment in which they are utilized.  In this sense they are templates meant to be consumed and tweaked to fit the specific constraints of the hardware available.  </li> <li>The CRs are applied against an OpenShift cluster in stages.  That is, there is an ordering in which each grouping of CRs is fed to the cluster.  It is not a case of simply taking all CRs from all stages and applying them all at once.</li> <li>YAML comments are placed throughout the CRs to aid in the process of customizing the CRs.  Fields that must (or most likely need to be) changed are commented with \"# CHANGEME\" either on the field itself or somewhere nearby.  Other comments are added to explain fields that can be changed and, sometimes, to explain additions that can be made.</li> <li>Each stage directory contains an overview README describing what is being accomplished by that set of CRs.</li> <li>Between stages 5 and 6, it is assumed that the user installs CephHCI on the 3 OSP compute nodes.  OpenStack K8S CRDs do not provide a way to install CephHCI via any sort of combination of CRs.</li> </ol>"},{"location":"#stages","title":"Stages","text":"<p>All stages must be executed in the order listed below.  Everything is required unless otherwise indicated.</p> <ol> <li>Install dependencies for the OpenStack K8S operators</li> <li>Install the OpenStack K8S operators</li> <li>Configuring networking on the OCP nodes</li> <li>Configure and deploy the control plane</li> <li>Configure and deploy the initial data plane to prepare for CephHCI installation</li> <li>Update the control plane and finish deploying the data plane after CephHCI has been installed</li> </ol>"},{"location":"stage1/","title":"Stage 1","text":"<p>Install the dependencies for Red Hat OpenStack Services on OpenShift operators</p>"},{"location":"stage1/#notes","title":"Notes","text":"<p>Requires an OpenShift 4.12+ cluster with 3 master/worker combo-nodes</p>"},{"location":"stage1/#steps","title":"Steps","text":"<ol> <li>Create Namespaces <pre><code>oc apply -f cert_manager_namespace.yaml -f metallb_namespace.yaml -f nmstate_namespace.yaml\n</code></pre></li> <li>Create OperatorGroups <pre><code>oc apply -f cert_manager_operatorgroup.yaml -f metallb_operatorgroup.yaml -f nmstate_operatorgroup.yaml\n</code></pre></li> <li>Create Subscriptions <pre><code>oc apply -f cert_manager_subscription.yaml -f metallb_subscription.yaml -f nmstate_subscription.yaml\n\nwhile ! (oc get pod --no-headers=true -l name=cert-manager-operator -n cert-manager-operator| grep \"cert-manager-operator\"); do sleep 10; done\noc wait pod -n cert-manager-operator --for condition=Ready -l name=cert-manager-operator --timeout=300s\nwhile ! (oc get pod --no-headers=true -l app=cainjector -n cert-manager | grep \"cert-manager-cainjector\"); do sleep 10; done\noc wait pod -n cert-manager -l app=cainjector --for condition=Ready --timeout=300s\nwhile ! (oc get pod --no-headers=true -l app=webhook -n cert-manager | grep \"cert-manager-webhook\"); do sleep 10; done\noc wait pod -n cert-manager -l app=webhook --for condition=Ready --timeout=300s\nwhile ! (oc get pod --no-headers=true -l app=cert-manager -n cert-manager | grep \"cert-manager\"); do sleep 10; done\noc wait pod -n cert-manager -l app=cert-manager --for condition=Ready --timeout=300s\n\ntimeout 300 bash -c \"while ! (oc get pod --no-headers=true -l control-plane=controller-manager -n metallb-system | grep metallb-operator-controller); do sleep 10; done\"\noc wait pod -n metallb-system --for condition=Ready -l control-plane=controller-manager --timeout=300s\ntimeout 300 bash -c \"while ! (oc get pod --no-headers=true -l component=webhook-server -n metallb-system | grep metallb-operator-webhook); do sleep 10; done\"\noc wait pod -n metallb-system --for condition=Ready -l component=webhook-server --timeout=300s\n\ntimeout 300 bash -c \"while ! (oc get deployments/nmstate-operator -n openshift-nmstate); do sleep 10; done\"\noc wait deployments/nmstate-operator -n openshift-nmstate --for condition=Available --timeout=300s\n</code></pre></li> <li>Create Deploys <pre><code># MetalLB\noc apply -f metallb_deploy.yaml\ntimeout 300 bash -c \"while ! (oc get pod --no-headers=true -l component=speaker -n metallb-system | grep speaker); do sleep 10; done\"\noc wait pod -n metallb-system -l component=speaker --for condition=Ready --timeout=300s\n\n# NMState\noc apply -f nmstate_deploy.yaml\ntimeout 300 bash -c \"while ! (oc get pod --no-headers=true -l component=kubernetes-nmstate-handler -n openshift-nmstate| grep nmstate-handler); do sleep 10; done\"\noc wait pod -n openshift-nmstate -l component=kubernetes-nmstate-handler --for condition=Ready --timeout=300s\ntimeout 300 bash -c \"while ! (oc get deployments/nmstate-webhook -n openshift-nmstate); do sleep 10; done\"\noc wait deployments/nmstate-webhook -n openshift-nmstate --for condition=Available --timeout=300s\n</code></pre></li> </ol>"},{"location":"stage2/","title":"Stage 2","text":"<p>Install the Red Hat OpenStack Services on OpenShift operators</p>"},{"location":"stage2/#steps","title":"Steps","text":"<ol> <li>Create Namespaces <pre><code>oc apply -f namespaces.yaml\n</code></pre></li> <li>Create OperatorGroup <pre><code>oc apply -f operatorgroup.yaml\n</code></pre></li> <li>Create CatalogSource <pre><code>oc apply -f catalogsource.yaml\n</code></pre></li> <li>Create Subscription <pre><code>oc apply -f subscription.yaml\ntimeout 300 bash -c 'until $(oc get csv -l operators.coreos.com/openstack-operator.openstack-operators -n openstack-operators | grep -q Succeeded); do sleep 5; done'\n</code></pre></li> </ol>"},{"location":"stage3/","title":"Stage 3","text":"<p>Configure OCP cluster networking for OSP</p>"},{"location":"stage3/#steps","title":"Steps","text":"<ol> <li>Create NNCPs <pre><code>oc apply -f ocp_node_0_nncp.yaml -f ocp_node_1_nncp.yaml -f ocp_node_2_nncp.yaml\n# CHANGEME: Set \"osp/interface\" below to the interface you are using as your OSP NIC\noc wait nncp -l osp/interface=enp7s0 --for condition=available --timeout=300s\n</code></pre></li> <li>Create NetAttachs <pre><code>oc apply -f netattach_ctlplane.yaml -f netattach_internalapi.yaml -f netattach_storage.yaml -f netattach_tenant.yaml\n</code></pre></li> <li>Create MetalLB resources</li> </ol> <pre><code>oc apply -f metallb_ipaddresspools.yaml -f metallb_l2advertisement.yaml\n</code></pre> <p>A NetworkAttachmentDefinition is not required for storage management network since that network is used by OpenStackDataPlane nodes but not OpenStack pods hosted on OpenShift in this architecture.</p>"},{"location":"stage4/","title":"Stage 4","text":"<p>Deploy the control plane</p>"},{"location":"stage4/#steps","title":"Steps","text":"<ol> <li>Switch to \"openstack\" namespace <pre><code>oc project openstack\n</code></pre></li> <li>Create NetConfig <pre><code>oc apply -f netconfig.yaml\n</code></pre></li> <li>Create Secret <pre><code>oc apply -f osp-secrets.yaml\n</code></pre></li> <li>Create OpenStackControlPlane and wait for it to finish deploying <pre><code>oc apply -f openstackcontrolplane.yaml\noc wait osctlplane openstack-galera-network-isolation-3replicas --for condition=Ready --timeout=600s\n</code></pre></li> </ol>"},{"location":"stage5/","title":"Stage 5","text":"<p>Deploy the initial data plane to prepare for CephHCI installation</p>"},{"location":"stage5/#notes","title":"Notes","text":"<p>Requires 3 pre-provisioned compute nodes that are accessible via the control plane IPs enumerated in step 2's <code>OpenStackDataPlaneNodeSet</code> using the SSH credentials provided in step 1's <code>Secret</code>.</p>"},{"location":"stage5/#steps","title":"Steps","text":"<ol> <li>Create SSH Secret <pre><code>oc apply -f dataplanesshsecret.yaml\n</code></pre></li> <li>Create OpenStackDataPlaneNodeSet <pre><code>oc apply -f openstackdataplanenodeset.yaml\n</code></pre></li> <li>Create pre-Ceph OpenStackDataPlaneDeployment and wait for it to finish <pre><code>oc apply -f openstackdataplanedeployment.yaml\noc wait osdpd deployment-pre-ceph --for condition=Ready --timeout=720s\n</code></pre></li> </ol>"},{"location":"stage6/","title":"Stage 6","text":"<p>Finish deploying the data plane after Ceph is available</p>"},{"location":"stage6/#notes","title":"Notes","text":"<p>Assumes that a Ceph cluster is available</p> <p>During stage 6 the OpenStackDataPlaneNodeSet (openstackdataplanenodeset.yaml) and OpenStackControlPlane (openstackcontrolplane.yaml) are updated. New instances of these services are not created in stage 6. Thus, if you have modified these CRs beyond when they were created (stage 4 for OpenStackControlPlane and stage 5 for OpenStackDataPlaneNodeSet), then your personal changes could be lost when you run <code>oc apply</code> as described below. To avoid this, <code>diff</code> the files and apply the changes using <code>oc edit</code> or <code>oc patch</code> during steps 2 and 3 below.</p> <pre><code>diff -u stage4/openstackcontrolplane.yaml stage6/openstackcontrolplane.yaml\ndiff -u stage5/openstackdataplanenodeset.yaml stage6/openstackdataplanenodeset.yaml\n</code></pre>"},{"location":"stage6/#steps","title":"Steps","text":"<ol> <li>Create Secrets <pre><code>oc apply -f ceph_secret.yaml -f nova_ceph.yaml -f nova_migration_ssh_key.yaml\n</code></pre></li> <li>Update OpenStackControlPlane and wait for it to finish <pre><code>oc apply -f openstackcontrolplane.yaml\noc wait osctlplane openstack-galera-network-isolation-3replicas --for condition=Ready --timeout=300s\n</code></pre></li> <li>Update OpenStackDataPlaneNodeSet <pre><code>oc apply -f openstackdataplanenodeset.yaml\n</code></pre></li> <li>Create a post-Ceph OpenStackDataPlaneDeployment and wait for it to finish <pre><code>oc apply -f openstackdataplanedeployment.yaml\noc wait osdpd deployment-post-ceph --for condition=Ready --timeout=720s\n</code></pre></li> <li>Force Nova to discover all compute hosts <pre><code>oc rsh nova-cell0-conductor-0 nova-manage cell_v2 discover_hosts --verbose\n</code></pre></li> </ol>"},{"location":"contributing/documentation/","title":"Contributing to documentation","text":""},{"location":"contributing/documentation/#rendering-documentation-locally","title":"Rendering documentation locally","text":"<p>Install docs build requirements into virtualenv:</p> <pre><code>python3 -m venv local/docs-venv\nsource local/docs-venv/bin/activate\npip install -r docs/doc_requirements.txt\n</code></pre> <p>Serve docs site on localhost:</p> <pre><code>mkdocs serve\n</code></pre> <p>Click the link it outputs. As you save changes to files modified in your editor, the browser will automatically show the new content.</p>"}]}